{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de83ac9-9f66-4808-8c2f-9025d682f1ce",
   "metadata": {},
   "source": [
    "# Merging the scraped data with the public dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac921bf-0d04-4579-93ab-a7fa90b9d603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intro', 'Full Name', 'Workplace', 'Location', 'Connections', 'Photo', 'Followers', 'About', 'Experiences', 'Number of Experiences', 'Educations', 'Number of Educations', 'Licenses', 'Number of Licenses', 'Volunteering', 'Number of Volunteering', 'Skills', 'Number of Skills', 'Recommendations', 'Number of Recommendations', 'Projects', 'Number of Projects', 'Publications', 'Number of Publications', 'Courses', 'Number of Courses', 'Honors', 'Number of Honors', 'Scores', 'Number of Scores', 'Languages', 'Number of Languages', 'Organizations', 'Number of Organizations', 'Interests', 'Number of Interests', 'Activities', 'Number of Activities', 'Label']\n",
      "✅ New cleaned CSV created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the original CSV\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\patil\\\\Downloads\\\\LinkedIn_Dataset.csv\")\n",
    "\n",
    "# Step 2: Display all available columns (optional, for inspection)\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Step 3: Select columns of your choice\n",
    "selected_columns = [\n",
    "    'Full Name',\n",
    "    'Workplace',\n",
    "    'Location',\n",
    "    'About',\n",
    "    'Experiences',\n",
    "    'Educations',\n",
    "    'Skills',\n",
    "    'Connections'\n",
    "]\n",
    "\n",
    "# Step 4: Create a new DataFrame with only selected columns\n",
    "df_selected = df[selected_columns].copy()\n",
    "\n",
    "# Step 5: Check for missing values (optional)\n",
    "#print(df_selected.isnull().sum())\n",
    "\n",
    "# Step 6: Export to a new CSV\n",
    "df_selected.to_csv(\"cleaned_linkedin_profiles.csv\", index=False)\n",
    "\n",
    "print(\"✅ New cleaned CSV created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b69a41-aeb4-4ead-8dcd-ed9e3f239143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined dataset saved as linkedin_combined_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load both datasets\n",
    "scraped_df = pd.read_excel(\"C:\\\\Users\\\\patil\\\\Downloads\\\\linkedin_profiles.xlsx\")  # From your team\n",
    "public_df = pd.read_excel(\"C:\\\\Users\\\\patil\\\\Downloads\\\\cleaned_linkedin_profiles.xlsx\")  # Renamed columns to match\n",
    "\n",
    "# Helper to flatten dictionary-like experience entries\n",
    "def flatten_dict_column(col_val, key_map=None):\n",
    "    try:\n",
    "        data = ast.literal_eval(col_val)\n",
    "        if isinstance(data, dict):\n",
    "            items = []\n",
    "            for k, v in data.items():\n",
    "                if isinstance(v, dict):\n",
    "                    line = []\n",
    "                    for key, val in v.items():\n",
    "                        label = key_map.get(key, key) if key_map else key\n",
    "                        line.append(f\"{label}: {val}\")\n",
    "                    items.append(\", \".join(line))\n",
    "            return \" | \".join(items)\n",
    "    except:\n",
    "        return col_val\n",
    "    return col_val\n",
    "\n",
    "# Apply flattening\n",
    "public_df[\"Experience\"] = public_df[\"Experience\"].apply(lambda x: flatten_dict_column(x, {\n",
    "    \"Role\": \"Role\", \"Workplace\": \"Company\", \"Duration\": \"Duration\", \"Workplace Location\": \"Location\"\n",
    "}))\n",
    "public_df[\"Education\"] = public_df[\"Education\"].apply(lambda x: flatten_dict_column(x, {\n",
    "    \"Institute\": \"School\", \"Degree\": \"Degree\", \"Duration\": \"Years\"\n",
    "}))\n",
    "public_df[\"Skills\"] = public_df[\"Skills\"].apply(lambda x: flatten_dict_column(x))\n",
    "\n",
    "# Merge both\n",
    "combined_df = pd.concat([scraped_df, public_df], ignore_index=True)\n",
    "\n",
    "# Save final version\n",
    "combined_df.to_csv(\"linkedin_combined_clean.csv\", index=False)\n",
    "print(\"✅ Combined dataset saved as linkedin_combined_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc9464-f256-4538-84d9-17b67fd06ce6",
   "metadata": {},
   "source": [
    "# Checking the labels of the OCEAN model personality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91a87e8a-6842-4129-bab3-55657c65b807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EXT1\\tEXT2\\tEXT3\\tEXT4\\tEXT5\\tEXT6\\tEXT7\\tEXT8\\tEXT9\\tEXT10\\tEST1\\tEST2\\tEST3\\tEST4\\tEST5\\tEST6\\tEST7\\tEST8\\tEST9\\tEST10\\tAGR1\\tAGR2\\tAGR3\\tAGR4\\tAGR5\\tAGR6\\tAGR7\\tAGR8\\tAGR9\\tAGR10\\tCSN1\\tCSN2\\tCSN3\\tCSN4\\tCSN5\\tCSN6\\tCSN7\\tCSN8\\tCSN9\\tCSN10\\tOPN1\\tOPN2\\tOPN3\\tOPN4\\tOPN5\\tOPN6\\tOPN7\\tOPN8\\tOPN9\\tOPN10\\tEXT1_E\\tEXT2_E\\tEXT3_E\\tEXT4_E\\tEXT5_E\\tEXT6_E\\tEXT7_E\\tEXT8_E\\tEXT9_E\\tEXT10_E\\tEST1_E\\tEST2_E\\tEST3_E\\tEST4_E\\tEST5_E\\tEST6_E\\tEST7_E\\tEST8_E\\tEST9_E\\tEST10_E\\tAGR1_E\\tAGR2_E\\tAGR3_E\\tAGR4_E\\tAGR5_E\\tAGR6_E\\tAGR7_E\\tAGR8_E\\tAGR9_E\\tAGR10_E\\tCSN1_E\\tCSN2_E\\tCSN3_E\\tCSN4_E\\tCSN5_E\\tCSN6_E\\tCSN7_E\\tCSN8_E\\tCSN9_E\\tCSN10_E\\tOPN1_E\\tOPN2_E\\tOPN3_E\\tOPN4_E\\tOPN5_E\\tOPN6_E\\tOPN7_E\\tOPN8_E\\tOPN9_E\\tOPN10_E\\tdateload\\tscreenw\\tscreenh\\tintroelapse\\ttestelapse\\tendelapse\\tIPC\\tcountry\\tlat_appx_lots_of_err\\tlong_appx_lots_of_err\n",
      "0  4\\t1\\t5\\t2\\t5\\t1\\t5\\t2\\t4\\t1\\t1\\t4\\t4\\t2\\t2\\t2...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "1  3\\t5\\t3\\t4\\t3\\t3\\t2\\t5\\t1\\t5\\t2\\t3\\t4\\t1\\t3\\t1...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "2  2\\t3\\t4\\t4\\t3\\t2\\t1\\t3\\t2\\t5\\t4\\t4\\t4\\t2\\t2\\t2...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "3  2\\t2\\t2\\t3\\t4\\t2\\t2\\t4\\t1\\t4\\t3\\t3\\t3\\t2\\t3\\t2...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      "4  3\\t3\\t3\\t3\\t5\\t3\\t3\\t5\\t3\\t4\\t1\\t5\\t5\\t3\\t1\\t1...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"D:\\\\wwe\\\\archive\\\\IPIP-FFM-data-8Nov2018\\\\data-final.csv\")\n",
    "\n",
    "# Check the first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3f4de0d-0903-48e8-9ba2-3ba394926fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['EXT1', 'EXT2', 'EXT3', 'EXT4', 'EXT5', 'EXT6', 'EXT7', 'EXT8', 'EXT9',\n",
      "       'EXT10',\n",
      "       ...\n",
      "       'dateload', 'screenw', 'screenh', 'introelapse', 'testelapse',\n",
      "       'endelapse', 'IPC', 'country', 'lat_appx_lots_of_err',\n",
      "       'long_appx_lots_of_err'],\n",
      "      dtype='object', length=110)\n",
      "   EXT1  EXT2  EXT3  EXT4  EXT5  EXT6  EXT7  EXT8  EXT9  EXT10  ...  OPN3_E  \\\n",
      "0   4.0   1.0   5.0   2.0   5.0   1.0   5.0   2.0   4.0    1.0  ...  2959.0   \n",
      "1   3.0   5.0   3.0   4.0   3.0   3.0   2.0   5.0   1.0    5.0  ...  1684.0   \n",
      "2   2.0   3.0   4.0   4.0   3.0   2.0   1.0   3.0   2.0    5.0  ...  1644.0   \n",
      "3   2.0   2.0   2.0   3.0   4.0   2.0   2.0   4.0   1.0    4.0  ...  1977.0   \n",
      "5   3.0   3.0   4.0   2.0   4.0   2.0   2.0   3.0   3.0    4.0  ...  3656.0   \n",
      "\n",
      "   OPN4_E  OPN5_E  OPN6_E  OPN7_E  OPN8_E  OPN9_E  OPN10_E  testelapse  \\\n",
      "0  3411.0  2170.0  4920.0  4436.0  3116.0  2992.0   4354.0       234.0   \n",
      "1  3026.0  4742.0  3336.0  2718.0  3374.0  3096.0   3019.0       179.0   \n",
      "2  1683.0  2229.0  8114.0  2043.0  6295.0  1585.0   2529.0       186.0   \n",
      "3  3728.0  4128.0  3776.0  2984.0  4192.0  3480.0   3257.0       219.0   \n",
      "5  4352.0  2681.0  3272.0  2640.0  1568.0  1640.0   3192.0       196.0   \n",
      "\n",
      "   country  \n",
      "0       GB  \n",
      "1       MY  \n",
      "2       GB  \n",
      "3       GB  \n",
      "5       SE  \n",
      "\n",
      "[5 rows x 102 columns]\n"
     ]
    }
   ],
   "source": [
    "# Re-load the dataset with the correct delimiter (assuming it's a tab-separated file)\n",
    "df = pd.read_csv(\"D:\\\\wwe\\\\archive\\\\IPIP-FFM-data-8Nov2018\\\\data-final.csv\", delimiter='\\t')\n",
    "\n",
    "# Clean column names by stripping leading/trailing spaces and replacing tabs\n",
    "df.columns = df.columns.str.replace('\\t', ' ', regex=False)\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "# Now try filtering by IPC again\n",
    "df = df[df['IPC'] == 1]\n",
    "\n",
    "# Drop unnecessary metadata columns (optional)\n",
    "df = df.drop(columns=['dateload', 'screenw', 'screenh', 'introelapse', \n",
    "                      'endelapse', 'lat_appx_lots_of_err', 'long_appx_lots_of_err', 'IPC'])\n",
    "\n",
    "print(df.head())  # Check the result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d51f4a-fcd2-4e82-83c8-a611c297d120",
   "metadata": {},
   "source": [
    "# Merging the labels into one label:\n",
    "\n",
    "for example: All labels in the dataset from EXT1 to EXT10 will be combined into one label called Extraversion\n",
    "And the values for these 10 labels would be computed and a mean of those values would be assigned to the new merged column\n",
    "These values represent the scores given by different users to these sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b536c321-9759-4f20-898e-f2c7353e7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trait item lists\n",
    "extroversion_items = ['EXT1', 'EXT2', 'EXT3', 'EXT4', 'EXT5', 'EXT6', 'EXT7', 'EXT8', 'EXT9', 'EXT10']\n",
    "neuroticism_items = ['EST1', 'EST2', 'EST3', 'EST4', 'EST5', 'EST6', 'EST7', 'EST8', 'EST9', 'EST10']\n",
    "agreeableness_items = ['AGR1', 'AGR2', 'AGR3', 'AGR4', 'AGR5', 'AGR6', 'AGR7', 'AGR8', 'AGR9', 'AGR10']\n",
    "conscientiousness_items = ['CSN1', 'CSN2', 'CSN3', 'CSN4', 'CSN5', 'CSN6', 'CSN7', 'CSN8', 'CSN9', 'CSN10']\n",
    "openness_items = ['OPN1', 'OPN2', 'OPN3', 'OPN4', 'OPN5', 'OPN6', 'OPN7', 'OPN8', 'OPN9', 'OPN10']\n",
    "\n",
    "# Items to reverse score (1=strongly disagree → 5=strongly agree becomes 5→1)\n",
    "reverse_items = ['EXT2','EXT4','EXT6','EXT8','EXT10',\n",
    "                 'EST2','EST4',\n",
    "                 'AGR1','AGR3','AGR5','AGR7',\n",
    "                 'CSN2','CSN4','CSN6','CSN8',\n",
    "                 'OPN2','OPN4','OPN6']\n",
    "\n",
    "# Reverse score\n",
    "for item in reverse_items:\n",
    "    df[item] = 6 - df[item]  # because scale is 1–5\n",
    "\n",
    "# Compute average trait scores\n",
    "df['Extraversion'] = df[extroversion_items].mean(axis=1)\n",
    "df['Neuroticism'] = df[neuroticism_items].mean(axis=1)\n",
    "df['Agreeableness'] = df[agreeableness_items].mean(axis=1)\n",
    "df['Conscientiousness'] = df[conscientiousness_items].mean(axis=1)\n",
    "df['Openness'] = df[openness_items].mean(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a870d82c-00b8-4f83-9794-c8cc693945fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize each trait: above average = high, else low\n",
    "for trait in ['Extraversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness']:\n",
    "    df[trait + '_Label'] = df[trait] > df[trait].median()\n",
    "    df[trait + '_Label'] = df[trait + '_Label'].astype(int)  # 1 = High, 0 = Low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4cc00da-af39-4f2e-a7e8-e0f129f9f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep either scores or labels\n",
    "personality_df = df[['Extraversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness']]\n",
    "# OR\n",
    "# personality_df = df[['Extraversion_Label', 'Neuroticism_Label', 'Agreeableness_Label', 'Conscientiousness_Label', 'Openness_Label']]\n",
    "\n",
    "# Save if needed\n",
    "personality_df.to_csv(\"processed_personality_traits.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c38bd-c753-4197-984e-95f47ec15dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
